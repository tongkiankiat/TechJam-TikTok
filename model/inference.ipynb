{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76e161",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Model: mDeBERTa-v3-base\n",
    "# Load model directly\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch, re, joblib\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "# TODO: Add the review to test here\n",
    "sample = {\n",
    "  \"company_name\": \"McDonald's\",\n",
    "  \"review_date\": \"2025-08-29\",\n",
    "  \"text\": \"The new Spicy Tomato McChicken Set is wonderful for my wallet. The potato pops also go really well with it.\",\n",
    "  \"stars\": 5,\n",
    "  \"category\": \"food and beverages\"\n",
    "}\n",
    "\n",
    "# Constants\n",
    "MODEL_NAME = \"kiankiat/loc-review-classification-model\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the models\n",
    "tokenizer_model = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "classifier_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load the meta_classifier\n",
    "meta_path = hf_hub_download(repo_id=MODEL_NAME, filename=\"meta_classifier.joblib\")\n",
    "meta = joblib.load(meta_path)\n",
    "\n",
    "vocab = [\n",
    "    \"the\",\"i\",\"of\",\"was\",\"to\",\"a\",\"for\",\"in\",\"is\",\"it\",\"that\",\"at\",\"you\",\"my\",\"on\",\"with\",\"but\",\"this\",\"about\",\"its\",\n",
    "    \"and\",\"we\",\"me\",\"they\",\"are\",\"out\",\"their\",\"an\",\"our\",\"not\",\"been\",\"if\",\"service\",\"like\",\"also\",\"had\",\"so\",\"as\",\n",
    "    \"your\",\"all\",\"have\",\"ive\",\"from\",\"even\",\"here\",\"very\",\"just\",\"food\",\"never\",\"place\",\"were\",\"there\",\"amazing\",\n",
    "    \"honestly\",\"experience\",\"be\",\"good\",\"by\",\"get\",\"how\",\"people\",\"while\",\"staff\",\"new\",\"say\",\"heard\",\"time\",\"friend\",\n",
    "    \"call\",\"which\",\"check\",\"up\",\"dont\",\"or\",\"more\",\"code\",\"can\",\"great\",\"deals\",\"absolutely\",\"youre\",\"has\",\"meanwhile\",\n",
    "    \"when\",\"discount\",\"one\",\"told\",\"these\",\"really\",\"recently\",\"exclusive\",\"some\",\"visit\",\"crypto\",\"what\",\"im\",\"no\",\n",
    "    \"only\",\"us\",\"them\",\"offer\",\"any\",\"best\",\"now\",\"would\",\"recommend\",\"singapore\",\"care\",\"weather\",\"clinic\",\"unbeatable\",\n",
    "    \"got\",\"where\",\"will\",\"help\",\"loved\",\"life\",\"too\",\"offers\",\"looking\",\"did\",\"discovered\",\"miss\",\"day\",\"off\",\"cash\",\n",
    "    \"well\",\"made\",\"highly\",\"local\",\"nothing\",\"spent\",\"love\",\"www\",\"ever\",\"friendly\",\"she\",\"than\",\n",
    "    \"services\",\"back\",\"quick\",\"over\",\"restaurant\",\"nice\",\"definitely\",\"go\",\"always\",\"other\",\"bar\",\"last\"\n",
    "]\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = text or \"\"\n",
    "    return re.sub(r\"[\\'\\\"’.,:&@!#\\-\\(\\)0-9–—-−]\", \"\", text)\n",
    "\n",
    "def remove_escape_chars(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    cleaned = re.sub(r'[\\n\\t\\r\\f\\v]', ' ', text)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "def lowercase(text):\n",
    "  return text.lower()\n",
    "\n",
    "def text_to_array(review: str):\n",
    "    if review is None:\n",
    "        return [0.0] * len(vocab)\n",
    "    # Normalize: lowercase, remove punctuation, split on whitespace\n",
    "    review = remove_escape_chars(lowercase(remove_punct(review)))\n",
    "    tokens = set(review.split())\n",
    "    # Build the array\n",
    "    return [1.0 if word in tokens else 0.0 for word in vocab]\n",
    "\n",
    "sample[\"tfidf_score\"] = text_to_array(sample[\"text\"])\n",
    "\n",
    "def tokenize_for_inference(datarow):\n",
    "    cat = datarow[\"category\"]\n",
    "    rating = datarow[\"stars\"]\n",
    "\n",
    "    company = datarow[\"company_name\"].strip()\n",
    "    poi = f\"POI: {company} [CAT_{cat}] [RATING_{rating}]\"\n",
    "\n",
    "    text = datarow[\"text\"]\n",
    "    if text is None:\n",
    "        text = \"\"\n",
    "    else:\n",
    "        text = str(text).strip()\n",
    "\n",
    "    encoded = tokenizer_model(\n",
    "        text,\n",
    "        poi,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"   # so we can pass directly to model\n",
    "    )\n",
    "    return encoded\n",
    "\n",
    "inputs = tokenize_for_inference(sample)\n",
    "\n",
    "def tfidf_row(vec):\n",
    "    arr = np.asarray(vec, dtype=np.float32).reshape(1, -1)\n",
    "    return csr_matrix(arr)\n",
    "\n",
    "with torch.inference_mode():\n",
    "  logits = classifier_model(**inputs).logits\n",
    "  probs = torch.softmax(logits, dim=-1)\n",
    "  X_tfidf = tfidf_row(sample[\"tfidf_score\"])\n",
    "  X_meta = hstack([X_tfidf, csr_matrix(probs)], format=\"csr\")\n",
    "  pred = meta.predict(X_meta)[0]\n",
    "\n",
    "print(\"Transformer probs:\", probs.tolist())\n",
    "print(\"Meta prediction:\", pred)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
